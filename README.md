# ğŸ” PredicciÃ³n del Consumo de Combustible con Machine Learning

Este proyecto tiene como objetivo construir un modelo de regresiÃ³n para predecir el **consumo medio de combustible (`avg_fuel`)** en trayectos de vehÃ­culos pesados. Para ello, se utilizaron datos de telemetrÃ­a, distancia recorrida, velocidad, diferencias horarias, consumo acumulado y variables derivadas.

---

## ğŸ§  Objetivo del Proyecto

- Predecir el consumo medio de combustible (`avg_fuel`) en funciÃ³n de variables relacionadas con la conducciÃ³n.
- Identificar las variables mÃ¡s influyentes en el consumo.
- Obtener un modelo interpretable y Ãºtil para apoyar decisiones de eficiencia o sostenibilidad.

---

## ğŸ§± Estructura del Proyecto
â”œâ”€â”€ datathon.ipynb                  # Notebook principal con todo el flujo de trabajo

â”œâ”€â”€ datathon.py                    # VersiÃ³n en script Python (opcional)

â”œâ”€â”€ modelo_gradient_boosting.pkl   # Modelo entrenado y guardado (pickle)

â”œâ”€â”€ predicciones_avg_fuel.json     # Predicciones reales vs. predichas

â”œâ”€â”€ Datathon_definiciÃ³n_reto.pdf   # DescripciÃ³n del reto original (sin datos sensibles)

â””â”€â”€ .gitignore                     # Evita subir archivos innecesarios como .csv

> â— Los archivos `.csv` con datos crudos **no estÃ¡n incluidos** por razones de confidencialidad. El proyecto funciona a partir del `df1` ya procesado.

---

## ğŸ§ª Flujo del Proyecto

### 1. Carga y exploraciÃ³n de datos
- Se trabajÃ³ principalmente con un Ãºnico DataFrame (`df1`) que incluÃ­a informaciÃ³n de posiciones GPS, velocidades, odÃ³metros, consumo acumulado (`Tfu`), etc.
- Se crearon variables nuevas como:
  - `consumo_por_km = avg_fuel / distanceMarker`
  - `velocidad_por_hora = distanceMarker / time_diff`
  - `con_peaje_rapido = (Is_toll_removed == 0) & (avg_speed > 90)`

### 2. Limpieza y preparaciÃ³n
- Se imputaron nulos, eliminaron duplicados y se eliminaron columnas con **alta correlaciÃ³n** (corr > 0.85).
- Se revisaron posibles columnas con **baja varianza**, pero no fue necesario eliminarlas.

### 3. SelecciÃ³n de variables
- Se seleccionaron 12 variables relevantes para el modelo basadas en el anÃ¡lisis de correlaciÃ³n y sentido del negocio.

### 4. DivisiÃ³n del dataset
- DivisiÃ³n 70% entrenamiento / 30% test usando `train_test_split`.

### 5. Torneo de modelos (model competition)
Se compararon cuatro modelos usando MAE, RMSE y RÂ² como mÃ©tricas:

| Modelo              | MAE     | RMSE    | RÂ²       |
|---------------------|---------|---------|----------|
| Linear Regression   | 0.0665  | 1.3896  | 0.0032   |
| Decision Tree       | 0.0129  | 0.9530  | 0.5311   |
| Random Forest       | 0.0110  | 0.9164  | 0.5664   |
| **Gradient Boosting** | **0.0245** | **0.9031** | **0.5789** |

> ğŸ” **Gradient Boosting** fue seleccionado como el modelo ganador por su mejor equilibrio entre precisiÃ³n y capacidad explicativa (RÂ² mÃ¡s alto).

### 6. Interpretabilidad con SHAP
- Se utilizÃ³ `shap` para analizar la importancia de cada variable en el modelo.
- Las 3 variables mÃ¡s influyentes fueron:
  - `consumo_por_km` (+0.27 SHAP mean)
  - `distance_diff` (+0.17 SHAP mean)
  - `distanceMarker` (+0.10 SHAP mean)

### 7. ExportaciÃ³n de resultados
- Modelo guardado como `.pkl` con `pickle`.
- Predicciones exportadas a `.json` en formato:

```json
[
  { "real": 0.1296, "predicha": 0.1012 },
  { "real": 0.0303, "predicha": 0.0323 },
  ...
]



ğŸ“ˆ MÃ©trica final del modelo

El modelo de Gradient Boosting alcanzÃ³ un RÂ² de 0.579, lo que significa que explica aproximadamente el 58% de la variabilidad en el consumo de combustible. Considerando la naturaleza ruidosa de los datos reales de telemetrÃ­a, es un resultado robusto y valioso para la toma de decisiones estratÃ©gicas.

ğŸ“š LibrerÃ­as utilizadas
	â€¢	pandas, numpy, matplotlib, seaborn
	â€¢	scikit-learn: modelos y mÃ©tricas
	â€¢	shap: interpretabilidad
	â€¢	pickle y json: exportaciÃ³n de modelo y predicciones
